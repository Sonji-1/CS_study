# File System(in SSAFY study)

# 설명 전 전제조건

본 문서에서는 UNIX에서 다루는 File System의 개괄에 대해 설명.

각 OS마다 File System을 핸들링하는 방식이나 그 구조에서 차이가 극명하므로, 모든 내용을 담기엔 종류가 지나치게 방대할 것으로 예상.

따라서, File System의 기본적인 요소를 모두 포함하고 있는 UNIX에서 File System + Virtual File System에 대해 설명. 

또한, 생소할 수 있는 용어와 개념이 너무 많아 전반적인 흐름을 한 차례 설명하고, 각 자세한 동작 방식은 후술.

# File

## 정의

논리적으로 연관된 데이터의 집합. 우리가 익히 알고있는 file 안에는 단순히 데이터 바이트 스트림만 존재

→ 이름, 마지막 수정일, 위치, 관리자 등 모든 Metadata는 별도 블록에 저장됨

- 권한, 소유자, 크기, 위치, 타임스탬프 등 : **inode**에 기록
- inode 번호와 파일 이름 매핑 : **Directory Entry**에 기록

⇒ File을 관리하기 위해 inode가 필요하고, 이 inode 등을 통해 file을 관리해주는 시스템이 File System

# File System

## 정의

운영체제가 보조기억장치에 데이터를 저장/조작/보호/복구 등 기능을 제공하는 소프트웨어 계층

→ 데이터와 메타데이터를 활용해 파일을 관리하는 시스템.

## 방식

슈퍼블록(Superblock)에 모든 파일 시스템에 관련된 내용을 저장하고, 파일 시스템이 마운트되면 OS는 이 정보를 읽어서 파일 핸들링 정보 획득. 이후 파일에 관련된 모든 동작은 이 슈퍼블록을 기반으로 동작

## 파일 참조 과정

![image.png](image.png)

위 과정처럼 동작하지만, 리눅스 커널에 기본으로 탑재된 파일 시스템 드라이버만 100가지가 넘음

(리눅스 네이티브, 레거시, 타OS 호환용, NFS, 특수목적 FS 등)

(아래 사진은 MacOS에서 FS 개수를 조회해본 결과)

![image.png](image%201.png)

### 구조

일반적으로 FS는 현실에서 폴더에 서류를 넣고, 폴더 안에 다시 서류철을 넣듯이, 직관적이고 관리하기 쉬운 tree 형태로 파일을 관리함.

이 경우, 수백만 개의 파일을 계층적으로 나누어 탐색 효율을 확보할 수 있고, 트리 경로로 고유하게 파일을 지정할 수 있음.

리눅스의 기본 철학인 `Everything is a file` 을 따르려면, 단일namespace에서 이런 다양한 자원을 동일한 인터페이스로 사용할 수 있어야 함.

![image.png](image%202.png)

### 단점은 없는가?

→ 모든 파일 시스템이 앞서 언급한 동작 순서와 같은 로직을 똑같이 따라줄 것이라고 보장할 수 없음.

⇒ **중간에 가상화 계층을 만들어서, FS 구조가 어떻든 위 흐름처럼 동작하도록 만들어서 해결**

= **가상 메모리처럼 파일 관리에도 가상 파일 시스템을 도입하자.**

# 가상 파일 시스템(Virtual File System : VFS)

## 정의

커널 안에서 여러 종류의 파일 시스템을 추상화해서, 공통 인터페이스로 제공하는 계층.

사용자는 파일 시스템의 구조/방식/구현 메소드 등에 대해 알 일 없이, 모두 동일한 동작으로 사용할 수 있음.

## 역할

유저 프로세스 쪽으로는 POSIX 표준 System call(open, read, write, close 등)을 동일하게 제공

- POSIX 표준(Portable Operating System Interface) : UNIX-like OS의 공통 API를 정리해서 이식성이 높은 유닉스 프로그램 개발용으로 책정한 국제 표준
    
    (글자 마지막의 X는 UNIX 호환 OS에 X가 붙는 것에서 유래함)
    
    (e.g., LINUX : Linux Is Not Unix + X)
    

파일 시스템 쪽으로는 각 파일 시스템의 구체적인 동작을 파일 연산 함수 포인터 테이블로 연결.

## 동작원리

1. FS가 마운트되면, 해당 드라이버(ext4/XFS/…)가 VFS에 자신의 연산 테이블을 등록
2. 파일 연산 명령어가 들어오면, VFS가 경로 탐색으로 inode를 획득
3. 앞서 1.에서 획득한 연산 테이블에 매핑되는 함수 포인터를 호출해서 동작 수행

e.g., 

`read(fd, buf, 100);` 을 실행했다고 가정(파일 100바이트를 읽어달라는 요청)

1. 마운트된 파일시스템이 자신의 연산 테이블을 미리 VFS에 등록
    - ext4 → `ext4_read()`
    - NFS → `nfs_read()`
    - FAT → `fat_read()`

2~3. 해당하는 파일의 inode를 획득하고, read 연산 수행

- VFS 입장에서는, `file->f_op->read()` 같이 포인터를 따라서 해당 파일시스템이 제공하는 코드를 호출

⇒ 사용자 입장에서는 똑같이 read(); 만 호출했을 뿐이지, 내부 구현이 어떻게 되는지는 상관하지 않음.

위 예시에서, ext4라면 드라이버가 디스크에서 블록을 읽고, NFS라면 네트워크를 통해 서버에 요청해서 데이터를 읽어오지만, 사용자 입장에서는 “파일을 읽어온다” 는 행위 자체만 알아도 충분함

![image.png](image%203.png)

⇒ 사실상 앞서 설명한 흐름 자체가 “가상 파일 시스템”의 동작 방식인 것. 

## 속도 향상에 대한 고찰

Q. FS는 아예 파일 입출력을 위해 별도로 존재할 만큼 굉장한 I/O 오버헤드가 발생할 것 같은데? 어떻게든 오버헤드를 줄여서 응답 속도를 올릴 방법이 없을까?

**→ 메모리에 캐시를 3 군데 배치하자.**

(캐시는 굳이 CPU 옆에있는 하드웨어가 아니어도 괜찮다. 단순히 본래 지정된 스토리지보다 더 빠른곳에 일부 데이터만 저장하고, 이를 통해 속도를 향상시킬 수 있다면 다 캐싱이라고 보아도 된다.)

(아래 페이지 참조)

[Memory Hierarchy](https://www.notion.so/Memory-Hierarchy-258d9a3d0f1c80daab3ae9ddd5b87929?pvs=21)

### Inode Cache(iCache)

최근 접근한 **inode 구조체를 통째로 저장**해서, 같은 파일을 여러 번 접근할 때 매번 디스크로 내려가지 않아도 되도록 캐싱.

권한 검사, 파일크기 확인, 타임스탬프 갱신 같은 **메타데이터 작업 능률 향상**

**요약 : 파일 속성 캐시**

### Dentry Cache(dCache)

경로 컴포넌트 단위로 파일 이름↔inode 매핑 정보를 캐싱. 매 경로탐색마다 디렉토리 블록을 읽어서 inode를 탐색하는 일 자체가 느림. 이 경로 자체를 캐싱해서 탐색 속도를 올려보자는 컨셉

**dCache는 실패도 캐싱한다는 특징이 있음**

- Positive Dentry : 존재하는 이름 ↔ inode 매핑 정보를 캐싱
- Negative Dentry : “이름이 없음”도 캐싱해서 실패 반복을 방지함

⇒ 지역성 원리 자체는 동일한데, 일반적으로 한 시스템이 반복해서 한 경로, 파일에 액세스하는 경우가 많으므로, 실패 자체도 캐싱해서 빠르게 “실패했음” 을 알리는 응답 자료로 사용할 수 있음.

**요약 : 경로 캐시**

### page Cache

파일의 실제 데이터 블록 내용을 페이지 단위로 캐싱

일반적으로 **L1 캐시 ↔ 메모리 구조**에서 사용한 캐싱 로직을, **메모리 ↔ 보조기억장치** 에도 적용했다고 보면 편함

⇒ RW 과정에서 발생하는 오버헤드를 줄이자는 목적, 쓰기 동작에서 dirty bit를 사용하는 점 등, 웬만한 경우에서 그 목적과 방법이 일치함

**요약 : 파일 데이터 캐시**

---

# 개념설명

## Superblock

### 정의

파일 시스템 전체에 대한 메타데이터 블록.

### 역할

파일 시스템이 마운트될 때, OS는 이를 읽고, 아래 항목을 획득해서, 이후 모든 동작에 대한 청사진을 구축

1. 블록 크기와 개수 확인
2. inode 테이블 위치 획득
3. 여유 블록/inode 상태 확인

### 저장되는 정보

1. 파일시스템 전역 정보
    1. 블록 크기
    2. 전체 블록 수
    3. 전체 inode 수
2. 사용 상태
    1. 사용중인 블록 수 / 남은 블록 수
    2. 사용중인 inode 수 / 남은 inode 수
3. 구조적 위치
    1. inode 테이블 위치
    2. 데이터 블록 위치
    3. 블록 그룹 정보
4. FS 관리 정보
    1. FS 이름 / ID
    2. 버전 정보
    3. 마지막 마운트 시간, 검사 시간
    4. 상태 플래그
    5. 마운트 횟수

# inode

## 정의

Index node 의 준말. 

파일에 대한 메타데이터 정보를 표현하는 데이터 구조.

파일의 이름과 내용을 제외한 거의 모든 정보가 담겨 있음

해당 File System이 어떤 데이터를 어떻게 관리하느냐에 따라 내용이 다소 달라질 수 있지만, 본 문서에서는 근래 대부분 시스템과 OS의 기본이 되는 FreeBSD에서 사용하는 방식을 따름

→ FreeBSD : UNIX 계열 OS로, 서버/데스크탑에 상관없이 사용할 수 있는 범용 OS.

Apple, Cisco, Dell, Netflix, SONY 등이 FreeBSD에서 일부 시스템을 따와 자사 시스템에 통합

<linux/fs.h> 헤더에 구조와 핸들링 관련 함수, 구조체들이 정의되어 있음

참고 링크 : https://lwn.net/2001/0906/a/fs.h.php3

## 생김새

![image.png](image%204.png)

## 주요 요소

- Mode : 파일 타입과 권한
    - 일반 파일인지, 디렉토리인지 판단(UNIX FS에서는 디렉토리도 파일의 일부로 봄)
    - rwx 권한비트
- Owners : 파일 소유자와 그룹 ID
- Timestamp : 생성시간, 수정시간 등
- Size : 파일의 전체 크기
- Direct(0) ~ Direct(12) : 직접 블록 포인터
    - 데이터 블록의 직접 액세스 주소가 저장됨
        - (데이터) 블록(=Data Block) : 해당 파일의 바이트 스트림(=내용)이 위치하고있는 저장장치의 최소 단위
- Indirect Pointer : 간접 블록 포인터
    - Single Indirect : 데이터 블록을 가리키는 포인터 집합의 시작 주소를 가리킴
    - Double Indirect : 데이터 블록을 가리키는 포인터 집합을 가리키는 포인터 집합의 시작 주소를 가리킴
        
        ⇒ “포인터의 포인터” 라는 이야기. 쉽게 말해 이중 포인터(double pointer)
        
    - Triple Indirect : 위 Double Indirect에서 포인터 개념이 하나 추가된 개념. 삼중 포인터(Triple Pointer)
    
    → 왜 필요한가?
    
    ⇒ 최소 단위로 잘려있는 데이터 블록을 모두 가리킨다면, inode의 크기는 아래와 같은 한계에 부딪힘
    
    1. **inode의 크기를 관리 데이터 이외에도 `(지원 가능한 파일의 최대 크기 / 블록의 최소 크기) * 포인터 사이즈` 만큼 미리 확보해야 함**
        
        → inode 하나의 크기가 불필요하게 커짐
        
        → 지원 가능한 파일의 최대 크기와 전체 파일 개수가 반비례관계로 확정되기 때문에, 중간값을 찾는 일 자체가 오버헤드인데다, 저장 가능한 전체 파일 개수가 감소
        
    2. **inode의 크기를 가변으로 만들어야 함**
        
        → 파일과 inode는 1:1로 매핑되는데, 특정 파일에 접근하기 위해 몇번 inode인지, 그 위치가 어디인지 선형 탐색으로 찾아야 함
        
        (크기가 같으면 시작위치 + offset 처럼 O(1)로 찾을 수 있지만, 가변이면 그 번호의 inode가 어디있는지 알 방법이 없으므로 전부 다 찾아야 함)
        
    
    ⇒ 사용했을 때 장점은 부록 참고.
    
- Block count : 실제 파일에 할당된 블록 수
    - 실제 파일이라면 파일 크기에 비례하게 증가하겠지만, 희소 파일은 0이거나 그에 준할만큼 작음
        - 희소 파일(Sparse File) : 부록 참조.
- Reference Count : inode를 참조하고 있는 파일 이름의 개수
    - e.g., 만약 대상이 디렉토리라면, 자기 자신(`.`), 부모(`..`), 하위 디렉토리 엔트리 때문에 최소 2이상
- Flags : inode에 설정 가능한 특수 동작 플래그. OS, FS 구현에 따라 달라짐
    - e.g.,
        - `i`  : Immutable → 삭제/수정 불가
        - `d`  : no Dump → 백업 제외
        - `a` : Append only → 추가만 가능
- Generation Number : inode 재사용 판단용 번호
    - 파일이 지워지고 inode 번호가 재사용될 경우, 캐시 혼동을 막기 위해 사용
        - inode 번호만 가지고는 동일성 보장이 불가하기 때문에 세대 번호를 도입한 것
        - 주로 NFS(Network File System) 기 DFS(Distributed File System) 계열에서 많이 사용

## 실제 Ubuntu에서 확인하기

사용중인 FS, 마운트 위치 단위로 확보된 Inode의 최대 개수, 사용량을 볼 수 있음

![image.png](image%205.png)

각 항목별 순서는 아래 표와 같음

| inode 번호 | 권한/파일 유형 | 링크 수 | 소유자 | 소유그룹 | 파일 크기(b) | 최종 수정시간 | 이름 |
| --- | --- | --- | --- | --- | --- | --- | --- |

![image.png](image%206.png)

## Inode와 File간 매핑정보

![image.png](image%207.png)

## Directory Entry

### 정의

파일 이름과 inode 번호를 매핑하는 항목.

디렉토리는 결국 이름→inode 번호 로 매핑되는 테이블이고, 그 테이블 내 원소가 Directory Entry인것.

통상 이를 줄여서 Dentry로 부르기도 함

---

# Github 질문 목록

## 1. File Descriptor와 File System에 대해 설명해주세요.

### File Discriptor

정의 : 프로세스가 파일(UNIX에서 바라보는 모든 파일. 디렉토리, 소켓, 파이프, 장치 등 모두를 포함)을 열었을 때, 커널이 그 프로세스에게 반환하는 정수(integer) 핸들.

프로세스 입장에서는 이 번호가 열린 파일을 나타내는 번호가 되고, 커널 입장에서는 이 번호가 파일 객체를 가리키는 인덱스로 쓰임.

![image.png](image%208.png)

일반적으로 0은 표준입력, 1은 표준출력, 2는 표준에러로 시작하기 때문에, 남은 숫자들 중 가장 작은 숫자가 할당됨

→ 프로세스가 파일 읽기를 시도하는 경우, 커널이 남은 수 중에서 가장 작은 수를 리턴해준다는 이야기.

프로세스는 읽었던 파일에 대해 다시 액세스를 시도하는 경우, 방금 받았던 번호를 통해 연산을 수행함

e.g., 

`open("file.txt", 0_RDONLY);` 를 호출했다고 가정.

1. 커널은 해당 파일에 대해 inode + file struct를 준비
2. 해당 프로세스의 File Discriptor 테이블에서 빈 칸을 찾고, 이 파일 객체를 가리키도록 연결
3. 이 File Discriptor의 인덱스 번호를 반환
4. 이후 프로세스는 `read(3, buf, size)` 처럼 정수 File Discriptor를 통해 커널에 I/O 요청 수행
5. `close(3)` 호출 시 프로세스 내 FD 테이블에서 해제.
    
    이 과정에서, 해당 파일의 참조 수가 0이 되면 커널이 자원 정리
    
    → inode 구조 중 `reference counter` 가 이때 쓰임.
    

⇒ **File discriptor는 프로세스 단위로 열려있는 파일을 핸들링하는 번호표.**

**File system은 저장 장치(디스크/파티션) 단위로 파일/디렉토리 구조를 제공하는 논리적 구조.**

## 2. i-Node가 무엇인가요?

⇒ 파일의 메타데이터를 저장하는 파일. FS는 이를 모아둔 Superblock을 기반으로 동작함.

(자세한 내용은 위 용어설명의 inode 참조)

## 3. 프로그래밍 언어 상에서 제공하는 파일 관련 함수는 파일을 어떤 방식으로 읽어들이나요?

⇒ VFS에서 제공하는 POSIX 표준 System call을 호출함. 사용자 프로세스나 개발자는 실제로 물리 디스크에서 파일을 어떻게 가져와야할지, 어떤 FS 위에서 동작해야 할지에 대한 고민이 필요 없음. VFS 계층을 통해 FS 종류로부터 독립된 시스템 콜을 호출해서 파일 관련 함수를 동작함.

# 부록

## Indirect Block의 사용 의의

### 가정

고전형 포인터 방식(12개 direct + single/double/triple indirect)

블록 크기 B = 4096 byte

포인터 크기 P = 4byte

한 포인터 블록이 가리킬 수 있는 데이터 블록 수 N

$$
N = B/P = 4096/4 = 1024
$$

### 단계별 수용 용량

1. **Direct**
    
    $$
    12blocks * 4KB = 48KB
    $$
    
2. **Single Indirect**
    
    → 포인터 블록 1개가 1024개의 데이터 블록의 시작점을 가리킴
    

$$
1024 * 4KB = 4MB
$$

1. **Double Indirect**
    
    → 첫 번째 포인터 블록이 1024개의 두 번째 포인터 블록을 가리키고, 두 번째 포인터 블록은 다시 1024개의 데이터 블록을 가리킴
    
    $$
    1024 * 1024 * 4KB = 4GB
    $$
    
2. **Triple Indirect**
    
    →위 Double Indirect에서 가리키는 과정이 1번 더 추가됨
    

$$
1024 * 1024 * 1024 * 4KB = 4TB
$$

### 총합(이론상 데이터 최대 지원 용량)

위 모든 포인터를 전부 다 사용한다면, 1 ~ 4의 총합으로 구할 수 있음.

$$
4TB + 4GB + 4MB + 48KB
$$

→ 실제로는 간접 포인터 블록도 나름의 용량을 사용하는 등, 저장 공간 오버헤드와 관리하기 위한 오버헤드 등이 필요하므로 실제 수치는 달라질 수 있음.

### 일반식

Capacity : 총 가용 용량

N = B / P

direct개수 : D

B : 한 블록의 용량

$$
Capacity = (D + N + N^2 + N^3) * B
$$

## 희소 파일(Sparse File)

### 정의

내용은 커보이지만, 실제로는 내부가 비어있어서 디스크 블록을 차지하지 않는 파일

→ 겉보기에는 1GB 크기의 용량이어도, 거의 모든 부분이 0으로 채워져있고 실제 데이터는 8KB라고 가정.

이 경우, 블록 크기가 4KB라면 약 25만개의 블록이 필요하지만, 이 경우는 2개만 필요

### 왜 쓰는가?

PC에 VirtualBox를 설치하고 100GB로 가상 디스크를 할당하려는 상황이라고 가정.

만약 희소 파일이 없다면, 해당 가상머신을 위해 100GB를 할당해주어야 함

→ 생성 자체도 오래 걸리고, 실제 드라이브 공간도 바로 100GB를 잡아먹음

희소 파일을 쓴다면, “논리적 크기”는 100GB로 잡히지만 실제로는 OS가 쓰는 부분만 할당됨

→ 가상머신이 10GB만 쓴다면 드라이브도 실제로 10GB만 차지하지만, 가상머신 내에선 100GB를 쓸 수 있다고 표시됨

⇒ 이를 **얇은 프로비저닝(Thin Provisioning)** 이라고 함.

- 프로비저닝(Provisioning) : 사용자 요구에 맞춰 필요한 자원을 준비하고 할당해 사용 가능한 상태로 만드는 과정.
    
    클라우드 관련 내용 중 IaaS(Infrastructure as a Service)처럼, 컴퓨팅 리소스, 스토리지, 네트워크 등을 요구에 맞게 할당해주는 것.
    

### 용례

1. 가상머신 디스크(위에서 설명)
2. DBMS 로그 파일
3. 과학 계산 / 시뮬레이션

### 명령어 예시

궁금하다면 직접 해보길 권장.

```bash
# 1GB 희소 파일 생성
truncate -s 1G sparse.img

# 논리적 크기 확인
ls -lh sparse.img
# -rw-r--r-- 1 user user 1.0G ... sparse.img

# 실제 점유 확인
du -h sparse.img
# 0   sparse.img  (아직 블록 없음)

# 파일에 5바이트 쓰기
echo "hello" > sparse.img

du -h sparse.img
# 4.0K   sparse.img  (4KB 블록 하나만 점유)

```

### 참고자료

https://en.wikipedia.org/wiki/Sparse_file

https://learn.microsoft.com/ko-kr/azure/azure-local/manage/manage-thin-provisioning-23h2?view=azloc-2509&viewFallbackFrom=azloc-2503

---

# 참고자료

https://wooooozin.tistory.com/entry/%ED%8C%8C%EC%9D%BC-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EA%B0%9C%EB%85%90%EA%B3%BC-inode-%EC%9E%91%EB%8F%99-%EB%B0%A9%EC%8B%9D-%EC%9D%B4%ED%95%B4

https://m.blog.naver.com/kalua8/222252555999

https://wikidocs.net/258817

https://reakwon.tistory.com/142

https://hyoje420.tistory.com/53

https://docs.kernel.org/filesystems/vfs.html

https://12bme.tistory.com/711

[File System](https://www.notion.so/File-System-a655b1805ee54d7f84c0a9c5267899e4?pvs=21)

https://ko.wikipedia.org/wiki/POSIX

https://dev-ahn.tistory.com/96

---

## 발표자료

[File_System_1.pdf](File_System_1.pdf)

[File_System_2.pdf](File_System_2.pdf)